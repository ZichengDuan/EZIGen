# checkpoint name
pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base"
checkpoint_path: /path/to/your/checkpoint # e.g. checkpoint-200000
clip_path: /path/to/ViT-B-32.pt # or simply "ViT-B/32" and let transformers module do its job

# system defaults, !no need to change anything here!
local_rank: 0 # we only do inference on a single GPU
resolution: 512
subject_denoise_timestep: 1
add_before_ca: true
sub_feat_position: "before_sa"
insert_adapter_at: all
infer_mode: true
gradient_accumulation_steps: 1
revision: null
non_ema_revision: null
enable_xformers_memory_efficient_attention: false
allow_tf32: false
scale_lr: false
use_8bit_adam: false
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 0.01
adam_epsilon: 0.00000001
max_grad_norm: 1.0
push_to_hub: false
hub_token: null
prediction_type: null
hub_model_id: null
dataloader_num_workers: 0
max_train_steps: null
snr_gamma: null
variant: null
residual_connection: true

# no need to change
infer_mode: true # we are now infer mode